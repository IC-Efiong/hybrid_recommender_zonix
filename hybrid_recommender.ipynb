{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1c86f69-a08a-4912-9a10-5f401238ebfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting surprise\n",
      "  Downloading surprise-0.1-py2.py3-none-any.whl.metadata (327 bytes)\n",
      "Collecting scikit-surprise (from surprise)\n",
      "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
      "     ---------------------------------------- 0.0/154.4 kB ? eta -:--:--\n",
      "     ------- ------------------------------- 30.7/154.4 kB 1.3 MB/s eta 0:00:01\n",
      "     --------- --------------------------- 41.0/154.4 kB 279.3 kB/s eta 0:00:01\n",
      "     -------------- ---------------------- 61.4/154.4 kB 363.1 kB/s eta 0:00:01\n",
      "     ---------------------- -------------- 92.2/154.4 kB 403.5 kB/s eta 0:00:01\n",
      "     ---------------------- -------------- 92.2/154.4 kB 403.5 kB/s eta 0:00:01\n",
      "     ---------------------------- ------- 122.9/154.4 kB 379.3 kB/s eta 0:00:01\n",
      "     -----------------------------------  153.6/154.4 kB 416.7 kB/s eta 0:00:01\n",
      "     ------------------------------------ 154.4/154.4 kB 400.5 kB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ice\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\ice\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\ice\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.13.1)\n",
      "Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (pyproject.toml): started\n",
      "  Building wheel for scikit-surprise (pyproject.toml): still running...\n",
      "  Building wheel for scikit-surprise (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp312-cp312-win_amd64.whl size=1291240 sha256=102a540d2635b95291c9bd1b51231679520933192f3e1aaea5625a1d631611e1\n",
      "  Stored in directory: c:\\users\\ice\\appdata\\local\\pip\\cache\\wheels\\75\\fa\\bc\\739bc2cb1fbaab6061854e6cfbb81a0ae52c92a502a7fa454b\n",
      "Successfully built scikit-surprise\n",
      "Installing collected packages: scikit-surprise, surprise\n",
      "Successfully installed scikit-surprise-1.1.4 surprise-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf0ddc1d-c107-421d-b015-54bf8f73c67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_factors': 50, 'n_epochs': 10, 'lr_all': 0.002, 'reg_all': 0.1}\n",
      "RMSE: 1.4260\n",
      "RMSE: 1.4260140070222234\n",
      "MAE:  1.2246\n",
      "MAE: 1.22463481441963\n",
      "Content-Based Recommendations for Product 10:\n",
      "   product_id       name category               description  premium\n",
      "0           1  Product 1  Fashion  Description of product 1        0\n",
      "1           2  Product 2  Fashion  Description of product 2        0\n",
      "2           3  Product 3     Home  Description of product 3        0\n",
      "3           4  Product 4     Home  Description of product 4        1\n",
      "4           5  Product 5   Beauty  Description of product 5        0\n",
      "Collaborative Recommendations for User 5:\n",
      "     product_id         name     category                 description  premium\n",
      "185         186  Product 186         Home  Description of product 186        0\n",
      "272         273  Product 273       Beauty  Description of product 273        0\n",
      "339         340  Product 340  Electronics  Description of product 340        0\n",
      "369         370  Product 370      Fashion  Description of product 370        0\n",
      "446         447  Product 447       Beauty  Description of product 447        0\n",
      "Social-Boosted Recommendations with Bias Mitigation for User 5:\n",
      "   product_id         name     category                 description  premium  \\\n",
      "0         370  Product 370      Fashion  Description of product 370        0   \n",
      "1         430  Product 430      Fashion  Description of product 430        0   \n",
      "2         485  Product 485      Fashion  Description of product 485        0   \n",
      "3         199  Product 199  Electronics  Description of product 199        0   \n",
      "4         340  Product 340  Electronics  Description of product 340        0   \n",
      "\n",
      "   liked  shared  \n",
      "0    0.0     0.0  \n",
      "1    0.0     0.0  \n",
      "2    0.0     0.0  \n",
      "3    0.0     0.0  \n",
      "4    0.0     0.0  \n",
      "Recommendations for New Users:\n",
      "     product_id         name     category                 description  premium\n",
      "76           77   Product 77  Electronics   Description of product 77        0\n",
      "185         186  Product 186         Home  Description of product 186        0\n",
      "337         338  Product 338       Beauty  Description of product 338        0\n",
      "358         359  Product 359         Home  Description of product 359        0\n",
      "367         368  Product 368         Home  Description of product 368        0\n",
      "Recommendations for New Products:\n",
      "     product_id         name category                 description  premium\n",
      "499         500  Product 500   Sports  Description of product 500        0\n",
      "498         499  Product 499     Home  Description of product 499        0\n",
      "497         498  Product 498   Sports  Description of product 498        0\n",
      "496         497  Product 497     Home  Description of product 497        0\n",
      "495         496  Product 496   Beauty  Description of product 496        0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ICE\\AppData\\Local\\Temp\\ipykernel_6844\\1420063789.py:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  recommendations['bias_adjustment'] = recommendations['category'].map(category_boost).fillna(1)\n",
      "C:\\Users\\ICE\\AppData\\Local\\Temp\\ipykernel_6844\\1420063789.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  recommendations['final_score'] = recommendations['bias_adjustment'] + 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split, GridSearchCV\n",
    "from surprise.accuracy import rmse, mae\n",
    "from sklearn.metrics import ndcg_score, precision_score, recall_score\n",
    "\n",
    "# Generate synthetic users\n",
    "def generate_users(n=1000):\n",
    "    return pd.DataFrame({\n",
    "        'user_id': range(1, n+1),\n",
    "        'age': np.random.randint(18, 60, n),\n",
    "        'location': np.random.choice(['NY', 'LA', 'SF', 'TX', 'CHI'], n),\n",
    "    })\n",
    "\n",
    "# Generate synthetic products\n",
    "def generate_products(n=500):\n",
    "    categories = ['Electronics', 'Fashion', 'Home', 'Beauty', 'Sports']\n",
    "    return pd.DataFrame({\n",
    "        'product_id': range(1, n+1),\n",
    "        'name': [f'Product {i}' for i in range(1, n+1)],\n",
    "        'category': np.random.choice(categories, n),\n",
    "        'description': [f'Description of product {i}' for i in range(1, n+1)],\n",
    "        'premium': np.random.choice([0, 1], n, p=[0.9, 0.1])  # 10% premium products\n",
    "    })\n",
    "\n",
    "# Generate synthetic interactions with social engagement\n",
    "def generate_interactions(users, products, n=5000):\n",
    "    interactions = []\n",
    "    for _ in range(n):\n",
    "        interactions.append({\n",
    "            'user_id': random.choice(users['user_id'].values),\n",
    "            'product_id': random.choice(products['product_id'].values),\n",
    "            'rating': random.randint(1, 5),\n",
    "            'liked': random.choice([0, 1]),\n",
    "            'shared': random.choice([0, 1]),\n",
    "        })\n",
    "    return pd.DataFrame(interactions)\n",
    "\n",
    "# Create datasets\n",
    "users_df = generate_users()\n",
    "products_df = generate_products()\n",
    "interactions_df = generate_interactions(users_df, products_df)\n",
    "\n",
    "# Implement Content-Based Filtering\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(products_df['description'])\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "def recommend_products_content_based(product_id, top_n=5):\n",
    "    idx = products_df.index[products_df['product_id'] == product_id].tolist()[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]\n",
    "    product_indices = [i[0] for i in sim_scores]\n",
    "    return products_df.iloc[product_indices]\n",
    "\n",
    "# Implement Collaborative Filtering (Hyperparameter Tuning)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(interactions_df[['user_id', 'product_id', 'rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "param_grid = {'n_factors': [50, 100], 'n_epochs': [10, 20], 'lr_all': [0.002, 0.005], 'reg_all': [0.02, 0.1]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "best_params = gs.best_params['rmse']\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "model = SVD(**best_params)\n",
    "model.fit(trainset)\n",
    "predictions = model.test(testset)\n",
    "\n",
    "print(\"RMSE:\", rmse(predictions))\n",
    "print(\"MAE:\", mae(predictions))\n",
    "\n",
    "\n",
    "def recommend_products_collaborative(user_id, top_n=5):\n",
    "    product_ids = products_df['product_id'].unique()\n",
    "    predictions = [model.predict(user_id, pid) for pid in product_ids]\n",
    "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "    recommended_ids = [pred.iid for pred in predictions[:top_n]]\n",
    "    return products_df[products_df['product_id'].isin(recommended_ids)]\n",
    "\n",
    "# Implement Bias Mitigation in Ranking\n",
    "def adjust_ranking_bias(recommendations, category_boost={'Fashion': 1.2, 'Electronics': 1.1}):\n",
    "    recommendations['bias_adjustment'] = recommendations['category'].map(category_boost).fillna(1)\n",
    "    recommendations['final_score'] = recommendations['bias_adjustment'] + 1\n",
    "    recommendations = recommendations.sort_values(by='final_score', ascending=False)\n",
    "    return recommendations.drop(columns=['bias_adjustment', 'final_score'])\n",
    "\n",
    "# Cold Start Handling for New Users\n",
    "def recommend_for_new_users(top_n=5):\n",
    "    popular_products = interactions_df.groupby('product_id').size().reset_index(name='count')\n",
    "    popular_products = popular_products.sort_values(by='count', ascending=False).head(top_n)\n",
    "    return products_df[products_df['product_id'].isin(popular_products['product_id'])]\n",
    "\n",
    "# Cold Start Handling for New Products\n",
    "def recommend_new_products(top_n=5):\n",
    "    latest_products = products_df.sort_values(by='product_id', ascending=False).head(top_n)\n",
    "    return latest_products\n",
    "\n",
    "# Integrate Social Media Engagement\n",
    "def recommend_with_social_boost(user_id, top_n=5, like_weight=0.2, share_weight=0.3):\n",
    "    recommendations = recommend_products_collaborative(user_id, top_n * 2)\n",
    "    recommendations = adjust_ranking_bias(recommendations)\n",
    "    interactions = interactions_df[interactions_df['user_id'] == user_id]\n",
    "    engagement_scores = interactions.groupby('product_id').agg({'liked': 'sum', 'shared': 'sum'}).reset_index()\n",
    "    engagement_scores['score'] = (engagement_scores['liked'] * like_weight) + (engagement_scores['shared'] * share_weight)\n",
    "    recommendations = recommendations.merge(engagement_scores, on='product_id', how='left').fillna(0)\n",
    "    recommendations['final_score'] = recommendations['score'] + 1\n",
    "    recommendations = recommendations.sort_values(by='final_score', ascending=False).head(top_n)\n",
    "    return recommendations.drop(columns=['score', 'final_score'])\n",
    "\n",
    "# Example recommendations\n",
    "sample_product_id = 10\n",
    "sample_user_id = 5\n",
    "print(f\"Content-Based Recommendations for Product {sample_product_id}:\")\n",
    "print(recommend_products_content_based(sample_product_id))\n",
    "print(f\"Collaborative Recommendations for User {sample_user_id}:\")\n",
    "print(recommend_products_collaborative(sample_user_id))\n",
    "print(f\"Social-Boosted Recommendations with Bias Mitigation for User {sample_user_id}:\")\n",
    "print(recommend_with_social_boost(sample_user_id))\n",
    "print(\"Recommendations for New Users:\")\n",
    "print(recommend_for_new_users())\n",
    "print(\"Recommendations for New Products:\")\n",
    "print(recommend_new_products())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eb0a51-236f-4a46-befb-ac1a09a591f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
